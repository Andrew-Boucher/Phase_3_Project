{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder, MinMaxScaler, RobustScaler, StandardScaler, FunctionTransformer\n",
    "from sklearn.metrics import plot_roc_curve, accuracy_score, confusion_matrix, mean_squared_error, roc_auc_score, r2_score                 \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV, train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.compose import ColumnTransformer\n",
    "# from sklearn.impute import SimpleImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "testv = pd.read_csv('../data/test_vals.csv')\n",
    "trainl = pd.read_csv('../data/training_labels.csv')\n",
    "trainv = pd.read_csv('../data/training_vals.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "functional                 32259\n",
       "non functional             22824\n",
       "functional needs repair     4317\n",
       "Name: status_group, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainl.status_group.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "idequality = (trainl['id'] == trainv['id'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.merge(trainv, trainl) #merging into one dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'status_group'}\n"
     ]
    }
   ],
   "source": [
    "print(set(data.columns).difference(set(trainv.columns))) # a sort of check to see if merge worked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testohe = OneHotEncoder()\n",
    "# dummy1 = pd.get_dummies(data['scheme_name'].dropna())\n",
    "# dummy2 = pd.get_dummies(data['status_group'].dropna())\n",
    "# testtree = DecisionTreeClassifier(max_depth=3)\n",
    "# testtree.fit(dummy1, dummy2 )/\n",
    "# testtree.score(data['scheme_name'], data['status_group'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pipe = Pipeline(steps=[\n",
    "#     ('scaler', StandardScaler),\n",
    "#     ('ohe', OneHotEncoder)\n",
    "#     ('polynom', PolynomialFeatures)\n",
    "# ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['communal standpipe', 'hand pump', 'other', 'improved spring',\n",
       "        'cattle trough', 'dam'], dtype=object),\n",
       " array(['communal standpipe', 'communal standpipe multiple', 'hand pump',\n",
       "        'other', 'improved spring', 'cattle trough', 'dam'], dtype=object))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['waterpoint_type_group'].unique(), data['waterpoint_type'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 59400 entries, 0 to 59399\n",
      "Data columns (total 41 columns):\n",
      " #   Column                 Non-Null Count  Dtype  \n",
      "---  ------                 --------------  -----  \n",
      " 0   id                     59400 non-null  int64  \n",
      " 1   amount_tsh             59400 non-null  float64\n",
      " 2   date_recorded          59400 non-null  object \n",
      " 3   funder                 55765 non-null  object \n",
      " 4   gps_height             59400 non-null  int64  \n",
      " 5   installer              55745 non-null  object \n",
      " 6   longitude              59400 non-null  float64\n",
      " 7   latitude               59400 non-null  float64\n",
      " 8   wpt_name               59400 non-null  object \n",
      " 9   num_private            59400 non-null  int64  \n",
      " 10  basin                  59400 non-null  object \n",
      " 11  subvillage             59029 non-null  object \n",
      " 12  region                 59400 non-null  object \n",
      " 13  region_code            59400 non-null  int64  \n",
      " 14  district_code          59400 non-null  int64  \n",
      " 15  lga                    59400 non-null  object \n",
      " 16  ward                   59400 non-null  object \n",
      " 17  population             59400 non-null  int64  \n",
      " 18  public_meeting         56066 non-null  object \n",
      " 19  recorded_by            59400 non-null  object \n",
      " 20  scheme_management      55523 non-null  object \n",
      " 21  scheme_name            31234 non-null  object \n",
      " 22  permit                 56344 non-null  object \n",
      " 23  construction_year      59400 non-null  int64  \n",
      " 24  extraction_type        59400 non-null  object \n",
      " 25  extraction_type_group  59400 non-null  object \n",
      " 26  extraction_type_class  59400 non-null  object \n",
      " 27  management             59400 non-null  object \n",
      " 28  management_group       59400 non-null  object \n",
      " 29  payment                59400 non-null  object \n",
      " 30  payment_type           59400 non-null  object \n",
      " 31  water_quality          59400 non-null  object \n",
      " 32  quality_group          59400 non-null  object \n",
      " 33  quantity               59400 non-null  object \n",
      " 34  quantity_group         59400 non-null  object \n",
      " 35  source                 59400 non-null  object \n",
      " 36  source_type            59400 non-null  object \n",
      " 37  source_class           59400 non-null  object \n",
      " 38  waterpoint_type        59400 non-null  object \n",
      " 39  waterpoint_type_group  59400 non-null  object \n",
      " 40  status_group           59400 non-null  object \n",
      "dtypes: float64(3), int64(7), object(31)\n",
      "memory usage: 19.0+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info() #which to drop, which to encode, etc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: dropnas on all, make copy df drop some columns like ['date_recorded', 'latitude', 'longitude', 'wpt_name', 'num_private', 'region_code', 'district_code, 'lga', 'ward', 'subvillage', 'public_meeting', 'recorded_by', 'extraction_type', 'extraction_type_group', 'management_group', 'payment_type', 'water_quality', 'quantity_group', 'source_type', 'source_class', 'waterpoint_type']\n",
    "\n",
    "\n",
    "^^ all but 'region' for location, then some unhelpful others such as ones without clear description\n",
    "\n",
    "&nbsp;\n",
    "\n",
    "get rid of zero val in construction_year \n",
    "change year into daterange from base year point\n",
    "\n",
    "&nbsp;\n",
    "\n",
    "check target as boolean vs multiclass vs maybe smoted functional but needs repair\n",
    "\n",
    "&nbsp;\n",
    "\n",
    "make narrative (stakeholder etc)\n",
    "\n",
    "&nbsp;\n",
    "\n",
    "dropnas, check for zeros, maybe convert bools, ordinal?, ohe, regression/normalize, model different versions (drop/dont scheme_name, drop/dont construction_year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dropt_cols = ['id', 'date_recorded', 'latitude', 'longitude', 'wpt_name', 'num_private', 'region_code', 'district_code', 'lga', 'ward', 'subvillage', 'public_meeting', 'recorded_by', 'extraction_type', 'extraction_type_group', 'management_group', 'payment_type', 'water_quality', 'quantity_group', 'source_type', 'source_class', 'waterpoint_type']\n",
    "\n",
    "len(dropt_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = data.drop(\n",
    "    ['date_recorded', 'latitude', 'longitude', 'wpt_name', \n",
    "     'num_private', 'region_code', 'district_code', 'lga',\n",
    "     'ward', 'subvillage', 'public_meeting', 'recorded_by', \n",
    "     'construction_year', 'extraction_type', \n",
    "     'extraction_type_group', 'management_group', 'payment_type',\n",
    "     'water_quality', 'quantity_group', 'source_type',\n",
    "     'source_class', 'waterpoint_type'],\n",
    "    axis=1)\n",
    "\n",
    "data1.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # is it possible to make a train test split function?\n",
    "# def ttsplit(X, y, n):\n",
    "#     Xtrain, Xtest, ytrain, ytest = train_test_split(X,y)\n",
    "# this was achieved in collab with Andrew, with a for loop iterating through a dictionary to name variables and run them through train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_cols_list = ['id','date_recorded', 'latitude', 'longitude', 'wpt_name',\n",
    "                  'num_private', 'region_code', 'district_code', 'lga', 'ward',\n",
    "                  'subvillage', 'public_meeting', 'recorded_by', 'extraction_type', \n",
    "                  'extraction_type_group', 'management_group', 'payment_type', 'water_quality',\n",
    "                  'quantity_group', 'source_type', 'source_class', 'waterpoint_type']\n",
    "\n",
    "df1 = data.drop(drop_cols_list, axis=1)\n",
    "df2 = df1.dropna()\n",
    "df3 = df2.drop(df2.loc[df2['construction_year']==0].index)\n",
    "data_all = df3 \n",
    "df4 = df1.drop('scheme_name', axis=1)\n",
    "df5 = df4.dropna()\n",
    "df6 = df5.drop(df5.loc[df5['construction_year']==0].index)\n",
    "data_no_sname = df6\n",
    "df7 = df1.drop('construction_year', axis=1)\n",
    "df8 = df7.dropna()\n",
    "data_no_constr = df8\n",
    "df9 = df1.drop(['scheme_name', 'construction_year'], axis=1)\n",
    "df10 = df9.dropna()\n",
    "data_no_sname_no_constr = df10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list = {'data_all': data_all, 'data_no_sname': data_no_sname, 'data_no_constr': data_no_constr, 'data_no_sname_no_constr': data_no_sname_no_constr}\n",
    "df_dic = {}\n",
    "\n",
    "for key, value in df_list.items():\n",
    "    X = value.drop('status_group', axis=1)\n",
    "    y = value['status_group']\n",
    "    z = key\n",
    "    df_dic[\"X_train_\" + z], df_dic[\"X_test_\" + z], df_dic[\"y_train_\" + z], df_dic[\"y_test_\" + z] = train_test_split(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def grab_numeric(df):\n",
    "#     return df.select_dtypes(include=['float', 'int'])\n",
    "# GrabNum = FunctionTransformer(grab_numeric)\n",
    "\n",
    "def grab_numeric(df):\n",
    "    df = pd.DataFrame(df)\n",
    "    return df.select_dtypes(include=['float', 'int']) \n",
    "\n",
    "GrabNum = FunctionTransformer(grab_numeric)\n",
    "\n",
    "subpipe_num = Pipeline(steps = [('grab_num', GrabNum), ('scaler', StandardScaler())])\n",
    "\n",
    "def grab_categorical(df):\n",
    "    df = pd.DataFrame(df)\n",
    "    return df.select_dtypes(include=['object'])\n",
    "\n",
    "GrabCat = FunctionTransformer(grab_categorical)\n",
    "\n",
    "subpipe_cat = Pipeline(steps = [('grab_cat', GrabCat),\n",
    "                                ('ohe', OneHotEncoder(sparse=False, handle_unknown='ignore'))])\n",
    "\n",
    "col_trans = ColumnTransformer(transformers=[('subpipe_num', subpipe_num, X.columns),\n",
    "                                            ('subpipe_cat', subpipe_cat, X.columns)]) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg_pipe = Pipeline(steps=[('col_trans', col_trans), ('logreg', LogisticRegression(max_iter=1000))]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    \"from sklearn.pipeline import Pipeline\\n\",\r\n",
      "    \"## Setting Up a Pipeline\"\r\n",
      "    \"numTrans = Pipeline(steps=[\\n\",\r\n",
      "    \"catTrans = Pipeline(steps=[\\n\",\r\n",
      "       \"                                 Pipeline(steps=[('scaler', StandardScaler())]),\\n\",\r\n",
      "       \"                                 Pipeline(steps=[('ohe',\\n\",\r\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42.7 s ± 1.83 s per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit logreg_pipe.fit(df_dic['X_train_data_all'], df_dic['y_train_data_all'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 14:59:40 up 38 days, 16:42,  0 users,  load average: 2.57, 3.96, 4.68\r\n"
     ]
    }
   ],
   "source": [
    "!uptime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 20 candidates, totalling 60 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-7)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=-7)]: Done  28 tasks      | elapsed: 65.7min\n",
      "[Parallel(n_jobs=-7)]: Done  60 out of  60 | elapsed: 138.9min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3,\n",
       "             estimator=Pipeline(steps=[('col_trans',\n",
       "                                        ColumnTransformer(transformers=[('subpipe_num',\n",
       "                                                                         Pipeline(steps=[('grab_num',\n",
       "                                                                                          FunctionTransformer(func=<function grab_numeric at 0x7fd7ed96d5e0>)),\n",
       "                                                                                         ('scaler',\n",
       "                                                                                          StandardScaler())]),\n",
       "                                                                         Index(['amount_tsh', 'funder', 'gps_height', 'installer', 'basin', 'region',\n",
       "       'population', 'scheme_management', 'permit', 'extracti...\n",
       "       'population', 'scheme_management', 'permit', 'extraction_type_class',\n",
       "       'management', 'payment', 'quality_group', 'quantity', 'source',\n",
       "       'waterpoint_type_group'],\n",
       "      dtype='object'))])),\n",
       "                                       ('logreg',\n",
       "                                        LogisticRegression(max_iter=1000))]),\n",
       "             n_jobs=-7,\n",
       "             param_grid={'logreg__C': [1.0, 10.0, 100.0, 1000.0, 10000.0],\n",
       "                         'logreg__penalty': ['l1', 'l2'],\n",
       "                         'logreg__solver': ['saga', 'lbfgs']},\n",
       "             verbose=3)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# logistic regression \n",
    "params = {}\n",
    "params['logreg__penalty'] = ['l1', 'l2']\n",
    "params['logreg__C'] = [1.0, 10.0, 100.0, 1000.0, 10000.0]\n",
    "params['logreg__solver'] = ['saga', 'lbfgs']\n",
    "# params['logreg__max_iter'] = []\n",
    "\n",
    "grid = GridSearchCV(logreg_pipe, param_grid=params, cv=3, n_jobs=-7, verbose=3)\n",
    "\n",
    "grid.fit(df_dic['X_train_data_all'], df_dic['y_train_data_all'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest_pipe = Pipeline(steps=[('col_trans', col_trans), ('forest', RandomForestClassifier())]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('col_trans',\n",
       "                 ColumnTransformer(transformers=[('subpipe_num',\n",
       "                                                  Pipeline(steps=[('grab_num',\n",
       "                                                                   FunctionTransformer(func=<function grab_numeric at 0x7fd7ed96d5e0>)),\n",
       "                                                                  ('scaler',\n",
       "                                                                   StandardScaler())]),\n",
       "                                                  Index(['amount_tsh', 'funder', 'gps_height', 'installer', 'basin', 'region',\n",
       "       'population', 'scheme_management', 'permit', 'extraction_type_class',\n",
       "       'management',...\n",
       "                                                                   FunctionTransformer(func=<function grab_categorical at 0x7fd7ed96d670>)),\n",
       "                                                                  ('ohe',\n",
       "                                                                   OneHotEncoder(handle_unknown='ignore',\n",
       "                                                                                 sparse=False))]),\n",
       "                                                  Index(['amount_tsh', 'funder', 'gps_height', 'installer', 'basin', 'region',\n",
       "       'population', 'scheme_management', 'permit', 'extraction_type_class',\n",
       "       'management', 'payment', 'quality_group', 'quantity', 'source',\n",
       "       'waterpoint_type_group'],\n",
       "      dtype='object'))])),\n",
       "                ('forest', RandomForestClassifier())])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest_pipe.fit(df_dic['X_train_data_all'], df_dic['y_train_data_all'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 36 candidates, totalling 108 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-2)]: Using backend LokyBackend with 7 concurrent workers.\n",
      "[Parallel(n_jobs=-2)]: Done  18 tasks      | elapsed:   16.4s\n",
      "[Parallel(n_jobs=-2)]: Done 108 out of 108 | elapsed:  3.1min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3,\n",
       "             estimator=Pipeline(steps=[('col_trans',\n",
       "                                        ColumnTransformer(transformers=[('subpipe_num',\n",
       "                                                                         Pipeline(steps=[('grab_num',\n",
       "                                                                                          FunctionTransformer(func=<function grab_numeric at 0x7fd7ed96d5e0>)),\n",
       "                                                                                         ('scaler',\n",
       "                                                                                          StandardScaler())]),\n",
       "                                                                         Index(['amount_tsh', 'funder', 'gps_height', 'installer', 'basin', 'region',\n",
       "       'population', 'scheme_management', 'permit', 'extracti...\n",
       "       'population', 'scheme_management', 'permit', 'extraction_type_class',\n",
       "       'management', 'payment', 'quality_group', 'quantity', 'source',\n",
       "       'waterpoint_type_group'],\n",
       "      dtype='object'))])),\n",
       "                                       ('forest', RandomForestClassifier())]),\n",
       "             n_jobs=-2,\n",
       "             param_grid={'forest__max_depth': [3, 5, 10],\n",
       "                         'forest__max_features': ['sqrt', 'log2'],\n",
       "                         'forest__min_samples_split': [200, 1000],\n",
       "                         'forest__n_estimators': [10, 100, 1000]},\n",
       "             verbose=3)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params0 = {}\n",
    "params0['forest__n_estimators'] = [10, 100, 1000]\n",
    "params0['forest__max_depth'] = [3, 5, 10]\n",
    "params0['forest__min_samples_split'] = [200, 1000]\n",
    "params0['forest__max_features'] = ['sqrt', 'log2']\n",
    "\n",
    "# params['logreg__max_iter'] = []\n",
    "\n",
    "grid0 = GridSearchCV(forest_pipe, param_grid=params0, cv=3, n_jobs=-2, verbose=3)\n",
    "\n",
    "grid0.fit(df_dic['X_train_data_all'], df_dic['y_train_data_all'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_pipe = Pipeline(steps=[('col_trans', col_trans), ('knn', KNeighborsClassifier())]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('col_trans',\n",
       "                 ColumnTransformer(transformers=[('subpipe_num',\n",
       "                                                  Pipeline(steps=[('grab_num',\n",
       "                                                                   FunctionTransformer(func=<function grab_numeric at 0x7fd7ed96d5e0>)),\n",
       "                                                                  ('scaler',\n",
       "                                                                   StandardScaler())]),\n",
       "                                                  Index(['amount_tsh', 'funder', 'gps_height', 'installer', 'basin', 'region',\n",
       "       'population', 'scheme_management', 'permit', 'extraction_type_class',\n",
       "       'management',...\n",
       "                                                                   FunctionTransformer(func=<function grab_categorical at 0x7fd7ed96d670>)),\n",
       "                                                                  ('ohe',\n",
       "                                                                   OneHotEncoder(handle_unknown='ignore',\n",
       "                                                                                 sparse=False))]),\n",
       "                                                  Index(['amount_tsh', 'funder', 'gps_height', 'installer', 'basin', 'region',\n",
       "       'population', 'scheme_management', 'permit', 'extraction_type_class',\n",
       "       'management', 'payment', 'quality_group', 'quantity', 'source',\n",
       "       'waterpoint_type_group'],\n",
       "      dtype='object'))])),\n",
       "                ('knn', KNeighborsClassifier())])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_pipe.fit(df_dic['X_train_data_all'], df_dic['y_train_data_all'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 16 candidates, totalling 48 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=-1)]: Done  48 out of  48 | elapsed:  7.2min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3,\n",
       "             estimator=Pipeline(steps=[('col_trans',\n",
       "                                        ColumnTransformer(transformers=[('subpipe_num',\n",
       "                                                                         Pipeline(steps=[('grab_num',\n",
       "                                                                                          FunctionTransformer(func=<function grab_numeric at 0x7fd7ed96d5e0>)),\n",
       "                                                                                         ('scaler',\n",
       "                                                                                          StandardScaler())]),\n",
       "                                                                         Index(['amount_tsh', 'funder', 'gps_height', 'installer', 'basin', 'region',\n",
       "       'population', 'scheme_management', 'permit', 'extracti...\n",
       "                                                                         Index(['amount_tsh', 'funder', 'gps_height', 'installer', 'basin', 'region',\n",
       "       'population', 'scheme_management', 'permit', 'extraction_type_class',\n",
       "       'management', 'payment', 'quality_group', 'quantity', 'source',\n",
       "       'waterpoint_type_group'],\n",
       "      dtype='object'))])),\n",
       "                                       ('knn', KNeighborsClassifier())]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'knn__n_neighbors': [3, 5, 7, 11], 'knn__p': [1, 2],\n",
       "                         'knn__weights': ['uniform', 'distance']},\n",
       "             verbose=3)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params1 = {}\n",
    "params1['knn__n_neighbors'] = [3, 5, 7, 11]\n",
    "params1['knn__weights'] = ['uniform', 'distance']\n",
    "params1['knn__p'] = [1, 2]\n",
    "\n",
    "grid1 = GridSearchCV(knn_pipe, param_grid=params1, cv=3, n_jobs=-1, verbose=3)\n",
    "\n",
    "grid1.fit(df_dic['X_train_data_all'], df_dic['y_train_data_all'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'logreg__C': 1.0, 'logreg__penalty': 'l2', 'logreg__solver': 'lbfgs'},\n",
       " {'forest__max_depth': 10,\n",
       "  'forest__max_features': 'sqrt',\n",
       "  'forest__min_samples_split': 200,\n",
       "  'forest__n_estimators': 100},\n",
       " {'knn__n_neighbors': 11, 'knn__p': 1, 'knn__weights': 'distance'})"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_params_, grid0.best_params_, grid1.best_params_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (learn-env)",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
